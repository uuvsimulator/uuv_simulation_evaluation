#!/usr/bin/env python
# Copyright (c) 2016 The UUV Simulator Authors.
# All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import roslib
import rospy
import os
import sys
import yaml
import itertools
import logging
import threading
import numpy as np
from time import sleep
from copy import deepcopy
from time import gmtime, strftime
from uuv_simulation_runner import SimulationRunner
from bag_evaluation import Evaluation
from bag_evaluation.metrics import KPI

roslib.load_manifest('uuv_simulation_wrapper')

def parse_input(args, input_map):
    p = vars(args)
    params = dict()
    for tag in input_map:
        if type(input_map[tag]) == list:
            p_cont = list()
            for elem in input_map[tag]:
                if type(elem) == str:
                    p_cont.append(p[elem])
                else:
                    p_cont.append(elem)
        else:
            if type(input_map[tag]) == str:
                p_cont = p[input_map[tag]]
            else:
                p_cont = input_map[tag]
        params[tag] = p_cont

    return params

def has_task_results(output_dir, task_filename):
    results_dir = os.path.join(output_dir, 'results', task_filename.replace('.yml', ''))
    if os.path.isdir(results_dir):
        has_results = False
        for item in os.listdir(results_dir):
            if '.bag' in item or 'process_log' in item:
                print 'Folder <%s> already contains results, skipping...' % results_dir
                has_results = True
        if has_results:
            return True
    return False

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run batch of simulations')
    parser.add_argument(
        '--task',
        type=str,
        default='task.yml')
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./results')
    parser.add_argument(
        '--config_file',
        type=str,
        default='batch_process_config.yml')

    logger = logging.getLogger('run_batch')
    out_hdlr = logging.StreamHandler(sys.stdout)
    out_hdlr.setFormatter(logging.Formatter('%(asctime)s | %(levelname)s | %(module)s | %(message)s'))
    out_hdlr.setLevel(logging.INFO)
    logger.addHandler(out_hdlr)
    logger.setLevel(logging.INFO)

    # Parse input arguments
    args = parser.parse_args(rospy.myargv()[1:])

    assert os.path.isfile(args.task), 'Task file is not a valid file'
    assert '.yml' in args.task or '.yaml' in args.task, 'Task file is not a YAML file'

    with open(args.task, 'r') as task_file:
        task_config = yaml.load(task_file)

    logger.info('Output directory = ' + args.output_dir)
    if not os.path.isdir(args.output_dir):
        os.makedirs(args.output_dir)
        logger.info('Output directory does not exist, creating <' + args.output_dir + '>')

    output_dir = os.path.abspath(args.output_dir)

    tasks_dir = os.path.join(output_dir, 'tasks')
    if not os.path.isdir(tasks_dir):
        os.makedirs(tasks_dir)
        logger.info('Task configuration directory does not exist, creating <' + tasks_dir + '>')

    # Load optimization configuration
    with open(args.config_file, 'r') as c_file:
        grid_config = yaml.load(c_file)

    assert 'parameters' in grid_config, 'List of input parameters not available'
    assert 'input_map' in grid_config, 'Input parameter map not available'

    # Generate the parameter vectors
    assert type(grid_config) == dict, 'List of parameters must be a dictionary'

    use_monte_carlo = False
    if 'use_monte_carlo' in grid_config:
        use_monte_carlo = grid_config['use_monte_carlo']
    params = dict()
    for tag in grid_config['parameters']:
        param_config = grid_config['parameters'][tag]
        if type(param_config) == list:
            params[tag] = param_config
        elif not use_monte_carlo:
            params[tag] = np.linspace(param_config['min'],
                                      param_config['max'],
                                      param_config['n'])
        else:
            params[tag] = range(param_config['n'])

        print tag, params[tag]

    for p in itertools.product(*params.values()):
        temp_task_file = 'task'
        # Temporary task configuration
        temp_task = deepcopy(task_config)
        # Copy the input map
        input_map = deepcopy(grid_config['input_map'])
        for tag, item in zip(params.keys(), p):
            for param_tag in input_map:
                if type(input_map[param_tag]) == list:
                    for i in range(len(input_map[param_tag])):
                        if input_map[param_tag][i] == tag:
                            if type(item) == str:
                                input_map[param_tag][i] = item
                            else:
                                input_map[param_tag][i] = float(item)
                else:
                    if input_map[param_tag] == tag:
                        if type(item) == str:
                            input_map[param_tag] = item
                        elif not use_monte_carlo:
                            input_map[param_tag] = float(item)
                        else:
                            input_map[param_tag] = \
                                float(np.random.random_sample(1)[0] * \
                                (grid_config['parameters'][tag]['max'] - grid_config['parameters'][tag]['min']) + grid_config['parameters'][tag]['min'])
                            item = input_map[param_tag]
            temp_task_file += '_' + tag + '_' + str(item)
        for tag in input_map:
            temp_task['execute']['params'][tag] = input_map[tag]
        temp_task_file = temp_task_file.replace('.', '-')
        temp_task_file = temp_task_file.replace('/', '-')
        temp_task_file = temp_task_file.replace(':', '-')
        temp_task_file += '.yml'

        temp_task_file_full_path = os.path.join(tasks_dir, temp_task_file)
        if not os.path.isfile(temp_task_file_full_path):
            with open(temp_task_file_full_path, 'w') as gs_file:
                yaml.dump(temp_task, gs_file, default_flow_style=False)
            logger.info('Task file created=' + os.path.basename(temp_task_file_full_path))
        else:
            logger.info('Task file already exists=' + os.path.basename(temp_task_file_full_path))

    threads = dict()
    # Run simulations
    for task in sorted(os.listdir(tasks_dir)):
        results_dir = os.path.join(output_dir, 'results', task.replace('.yml', ''))
        if os.path.isdir(results_dir):
            if has_task_results(results_dir, task):
                continue

        if not has_task_results(output_dir, task):
            try:
                logger.info('Starting simulation...')
                logger.info('\tTask=' + task)
                logger.info('\tResults directory=' + results_dir)

                time_offset = 5
                runner = SimulationRunner(dict(),
                                          os.path.join(tasks_dir, task),
                                          results_dir,
                                          True,
                                          add_folder_timestamp=False)

                runner.run(dict())

                logger.info('Start evaluation of the results, task=' + task)
                logger.info('\tTime offset for KPI evaluation[s]=' + str(time_offset))
                logger.info('\tResults files directory=' + runner.current_sim_results_dir)
                logger.info('\tROS bag file=' + runner.recording_filename)
                sim_eval = Evaluation(runner.recording_filename,
                                      runner.current_sim_results_dir,
                                      time_offset=time_offset)

                logger.info('Evaluation finished, task=' + task)

                sim_eval.compute_kpis()
                sim_eval.save_evaluation()

                del runner
                del sim_eval
                sleep(0.5)
            except Exception, e:
                logger.error('Error occured while executing task %s' % task)
                logger.error('  Message=' + str(e))
                sleep(0.5)
